{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f562c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "                              # import libraries #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7952b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "from keras.preprocessing import image, sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "                          # import paths #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3fb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.listdir(\"../input/flickr8k/flickr_data/Flickr_Data/\")\n",
    "images_path = '../input/flickr8k/flickr_data/Flickr_Data/Images/'\n",
    "captions_path = '../input/flickr8k/flickr_data/Flickr_Data/Flickr_TextData/Flickr8k.token.txt'\n",
    "train_path = '../input/flickr8k/flickr_data/Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt'\n",
    "val_path = '../input/flickr8k/flickr_data/Flickr_Data/Flickr_TextData/Flickr_8k.devImages.txt'\n",
    "test_path = '../input/flickr8k/flickr_data/Flickr_Data/Flickr_TextData/Flickr_8k.testImages.txt'\n",
    "\n",
    "captions = open(captions_path, 'r').read().split(\"\\n\")\n",
    "x_train = open(train_path, 'r').read().split(\"\\n\")\n",
    "x_val = open(val_path, 'r').read().split(\"\\n\")\n",
    "x_test = open(test_path, 'r').read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                # length of the train #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "                             # print the len #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0997a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(captions))\n",
    "captions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "\n",
    "for ix in range(len(captions)-1):\n",
    "    temp = captions[ix].split(\"#\")\n",
    "    if temp[0] in tokens:\n",
    "        tokens[temp[0]].append(temp[1][2:])\n",
    "    else:\n",
    "        tokens[temp[0]] = [temp[1][2:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acb05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "temp = captions[100].split(\"#\")\n",
    "z = Image(filename=images_path+temp[0])\n",
    "display(z)\n",
    "\n",
    "for ix in range(len(tokens[temp[0]])):\n",
    "    print(tokens[temp[0]][ix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_imgs=[]\n",
    "captions=[]\n",
    "for img in x_train:\n",
    "    if img == '':\n",
    "        continue\n",
    "    for capt in tokens[img]:\n",
    "        caption = \"<start> \"+ capt + \" <end>\"\n",
    "        x_imgs.append(img)\n",
    "        captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'images':x_imgs,'captions':captions}\n",
    "df=pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245969a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [i.split() for i in captions]\n",
    "unique = []\n",
    "for i in words:\n",
    "    unique.extend(i)\n",
    "unique = list(set(unique))\n",
    "print(len(unique))\n",
    "vocab_size = len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49802b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_indices = {val:index for index, val in enumerate(unique)}\n",
    "indices_2_word = {index:val for index, val in enumerate(unique)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec662030",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_indices['UNK'] = 0\n",
    "indices_2_word[0] = 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"w2i.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(word_2_indices, pickle_f )\n",
    "with open( \"i2w.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(indices_2_word, pickle_f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/img-cap-w2i-i2w/w2i (2).p', 'rb') as f:\n",
    "    word_2_indices= pickle.load(f, encoding=\"bytes\")\n",
    "with open('../input/img-cap-w2i-i2w/i2w (2).p', 'rb') as f:\n",
    "    indices_2_word= pickle.load(f, encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_2_indices.keys())\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d522c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in captions:\n",
    "    i = i.split()\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ad647",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences, subsequent_words = [], []\n",
    "for ix in tqdm(range(len(captions))):\n",
    "    partial_seqs = []\n",
    "    next_words = []\n",
    "    text = captions[ix].split()\n",
    "    text = [word_2_indices[i] for i in text]\n",
    "    for i in range(1, len(text)):\n",
    "        partial_seqs.append(text[:i])\n",
    "        next_words.append(text[i])\n",
    "    padded_partial_seqs = sequence.pad_sequences(partial_seqs, max_len, padding='post')\n",
    "    next_words_1hot = np.zeros([len(next_words), vocab_size], dtype=np.bool)\n",
    "    \n",
    "    for i,next_word in enumerate(next_words):\n",
    "        next_words_1hot[i, next_word] = 1\n",
    "        \n",
    "    padded_sequences.append(padded_partial_seqs)\n",
    "    subsequent_words.append(next_words_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310eaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img_path):\n",
    "    im = image.load_img(img_path, target_size=(224,224,3))\n",
    "    im = image.img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs={}\n",
    "for i in tqdm(x_train[:6000]):\n",
    "    if i in imgs.keys():\n",
    "        continue\n",
    "    path = images_path + i\n",
    "    img = preprocessing(path)\n",
    "    pred = model.predict(img).reshape(2048)\n",
    "    imgs[i]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92006c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b396de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"proces_imgs.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(imgs, pickle_f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eea688",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/img-cap-63-acc-model/proces_imgs.p', 'rb') as f:\n",
    "    imgs= pickle.load(f, encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    if df.iloc[i, 0] in imgs.keys():\n",
    "        img.append(imgs[df.iloc[i, 0]])\n",
    "\n",
    "img = np.asarray(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03818575",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "image_model = Sequential()\n",
    "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65faffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = Sequential()\n",
    "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
    "language_model.add(LSTM(256, return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
    "\n",
    "language_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb943639",
   "metadata": {},
   "outputs": [],
   "source": [
    "conca = Concatenate()([image_model.output, language_model.output])\n",
    "x = LSTM(128, return_sequences=True)(conca)\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "x = Dense(vocab_size)(x)\n",
    "out = Activation('softmax')(x)\n",
    "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c356056",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../input/img-cap-63-acc-model/best_model_acc (1).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_gen(inp,ne_words,batch_size=256):\n",
    "    cap=inp[1]\n",
    "    imgs=inp[0]\n",
    "    while True:\n",
    "        for i in range(0,30000-batch_size,batch_size):\n",
    "            n_words=[]\n",
    "            i_cap=[]\n",
    "            im=[]\n",
    "            for j in range(batch_size):\n",
    "                n_words.extend(ne_words[i+j].tolist())\n",
    "                i_cap.extend(cap[i+j].tolist())\n",
    "            for ix in range(i,i+batch_size):\n",
    "                for iy in range(cap[ix].shape[0]):\n",
    "                    im.append(imgs[ix])\n",
    "                \n",
    "            i_cap=np.array(i_cap)\n",
    "            n_words=np.asarray(n_words)\n",
    "            im= np.asarray(im)\n",
    "        \n",
    "            yield [im,i_cap],n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=tr_gen([img,padded_sequences],subsequent_words,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf852c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint('best_model_acc.h5', monitor = 'accuracy' , mode = 'max', verbose = 1 , save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c83553",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit_generator(train_gen,steps_per_epoch=30000//256,callbacks = [mc],epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99964a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img_path):\n",
    "    im = image.load_img(img_path, target_size=(224,224,3))\n",
    "    im = image.img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding(model, img):\n",
    "    image = preprocessing(img)\n",
    "    pred = model.predict(image).reshape(2048)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8123d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=os.listdir('../input/flickr8k/flickr_data/Flickr_Data/Images/')\n",
    "l[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b336669",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '../input/flickr8k/flickr_data/Flickr_Data/Images/'+l[4681]\n",
    "#img='../input/backgrd-sample-imgs/2019-02-10-13-40-01-855.jpg'\n",
    "test_img = get_encoding(resnet, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_captions(image):\n",
    "    start_word = [\"<start>\"]\n",
    "    while True:\n",
    "        par_caps = [word_2_indices[i] for i in start_word]\n",
    "        par_caps = sequence.pad_sequences([par_caps], maxlen=max_len, padding='post')\n",
    "        preds = model.predict([np.array([image]), np.array(par_caps)])\n",
    "        word_pred = indices_2_word[np.argmax(preds[0])]\n",
    "        start_word.append(word_pred)\n",
    "        \n",
    "        if word_pred == \"<end>\" or len(start_word) > max_len:\n",
    "            break\n",
    "            \n",
    "    return ' '.join(start_word[1:-1])\n",
    "\n",
    "Argmax_Search = predict_captions(test_img)\n",
    "z = Image(filename=img)\n",
    "display(z)\n",
    "\n",
    "print(Argmax_Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d324e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120de46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1be641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6234b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6b35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
